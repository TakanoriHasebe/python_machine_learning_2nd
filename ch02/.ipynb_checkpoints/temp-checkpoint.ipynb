{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdalineSGD(object):\n",
    "    \"\"\"ADAptive LInear NEuron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "      Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "      Passes over the training dataset.\n",
    "    shuffle : bool (default: True)\n",
    "      Shuffles training data every epoch if True to prevent cycles.\n",
    "    random_state : int\n",
    "      Random number generator seed for random weight\n",
    "      initialization.\n",
    "\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "      Weights after fitting.\n",
    "    cost_ : list\n",
    "      Sum-of-squares cost function value averaged over all\n",
    "      training samples in each epoch.\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=10, shuffle=True, random_state=None):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.w_initialized = False\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "          Training vectors, where n_samples is the number of samples and\n",
    "          n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "          Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        self._initialize_weights(X.shape[1])\n",
    "        self.cost_ = []\n",
    "        for i in range(self.n_iter):\n",
    "            if self.shuffle:\n",
    "                X, y = self._shuffle(X, y)\n",
    "            cost = []\n",
    "            for xi, target in zip(X, y):\n",
    "                cost.append(self._update_weights(xi, target))\n",
    "            avg_cost = sum(cost) / len(y)\n",
    "            self.cost_.append(avg_cost)\n",
    "        return self\n",
    "\n",
    "    def partial_fit(self, X, y):\n",
    "        \"\"\"Fit training data without reinitializing the weights\"\"\"\n",
    "        if not self.w_initialized:\n",
    "            self._initialize_weights(X.shape[1])\n",
    "        if y.ravel().shape[0] > 1:\n",
    "            for xi, target in zip(X, y):\n",
    "                self._update_weights(xi, target)\n",
    "        else:\n",
    "            self._update_weights(X, y)\n",
    "        return self\n",
    "\n",
    "    def _shuffle(self, X, y):\n",
    "        \"\"\"Shuffle training data\"\"\"\n",
    "        r = self.rgen.permutation(len(y))\n",
    "        return X[r], y[r]\n",
    "    \n",
    "    def _initialize_weights(self, m):\n",
    "        \"\"\"Initialize weights to small random numbers\"\"\"\n",
    "        self.rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = self.rgen.normal(loc=0.0, scale=0.01, size=1 + m)\n",
    "        self.w_initialized = True\n",
    "        \n",
    "    def _update_weights(self, xi, target):\n",
    "        \"\"\"Apply Adaline learning rule to update the weights\"\"\"\n",
    "        output = self.activation(self.net_input(xi))\n",
    "        error = (target - output)\n",
    "        self.w_[1:] += self.eta * xi.dot(error)\n",
    "        self.w_[0] += self.eta * error\n",
    "        cost = 0.5 * error**2\n",
    "        return cost\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\"Compute linear activation\"\"\"\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.activation(self.net_input(X)) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3               4\n",
       "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "149  5.9  3.0  5.1  1.8  Iris-virginica"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/'\n",
    "        'machine-learning-databases/iris/iris.data', header=None)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# select setosa and versicolor\n",
    "y = df.iloc[0:100, 4].values\n",
    "y = np.where(y == 'Iris-setosa', -1, 1)\n",
    "\n",
    "# extract sepal length and petal length\n",
    "X = df.iloc[0:100, [0, 2]].values\n",
    "\n",
    "# plot data\n",
    "plt.scatter(X[:50, 0], X[:50, 1],\n",
    "            color='red', marker='o', label='setosa')\n",
    "plt.scatter(X[50:100, 0], X[50:100, 1],\n",
    "            color='blue', marker='x', label='versicolor')\n",
    "\n",
    "plt.xlabel('sepal length [cm]')\n",
    "plt.ylabel('petal length [cm]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "# plt.savefig('images/02_06.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize features\n",
    "X_std = np.copy(X)\n",
    "X_std[:, 0] = (X[:, 0] - X[:, 0].mean()) / X[:, 0].std()\n",
    "X_std[:, 1] = (X[:, 1] - X[:, 1].mean()) / X[:, 1].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdalineSGD(object):\n",
    "    \"\"\"ADAptive LInear NEuron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "      Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "      Passes over the training dataset.\n",
    "    shuffle : bool (default: True)\n",
    "      Shuffles training data every epoch if True to prevent cycles.\n",
    "    random_state : int\n",
    "      Random number generator seed for random weight\n",
    "      initialization.\n",
    "\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "      Weights after fitting.\n",
    "    cost_ : list\n",
    "      Sum-of-squares cost function value averaged over all\n",
    "      training samples in each epoch.\n",
    "\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=10, shuffle=True, random_state=None):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.w_initialized = False\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "          Training vectors, where n_samples is the number of samples and\n",
    "          n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "          Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        self._initialize_weights(X.shape[1])\n",
    "        self.cost_ = []\n",
    "        for i in range(self.n_iter):\n",
    "            if self.shuffle:\n",
    "                X, y = self._shuffle(X, y)\n",
    "            cost = []\n",
    "            for xi, target in zip(X, y):\n",
    "                cost.append(self._update_weights(xi, target))\n",
    "            avg_cost = sum(cost) / len(y)\n",
    "            self.cost_.append(avg_cost)\n",
    "        return self\n",
    "\n",
    "    def partial_fit(self, X, y):\n",
    "        \"\"\"Fit training data without reinitializing the weights\"\"\"\n",
    "        if not self.w_initialized:\n",
    "            self._initialize_weights(X.shape[1])\n",
    "        if y.ravel().shape[0] > 1:\n",
    "            for xi, target in zip(X, y):\n",
    "                self._update_weights(xi, target)\n",
    "        else:\n",
    "            self._update_weights(X, y)\n",
    "        return self\n",
    "\n",
    "    def _shuffle(self, X, y):\n",
    "        \"\"\"Shuffle training data\"\"\"\n",
    "        r = self.rgen.permutation(len(y))\n",
    "        return X[r], y[r]\n",
    "    \n",
    "    def _initialize_weights(self, m):\n",
    "        \"\"\"Initialize weights to small random numbers\"\"\"\n",
    "        self.rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = self.rgen.normal(loc=0.0, scale=0.01, size=1 + m)\n",
    "        self.w_initialized = True\n",
    "        \n",
    "    def _update_weights(self, xi, target):\n",
    "        \"\"\"Apply Adaline learning rule to update the weights\"\"\"\n",
    "        output = self.activation(self.net_input(xi))\n",
    "        error = (target - output)\n",
    "        self.w_[1:] += self.eta * xi.dot(error)\n",
    "        self.w_[0] += self.eta * error\n",
    "        cost = 0.5 * error**2\n",
    "        return cost\n",
    "    \n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def activation(self, X):\n",
    "        \"\"\"Compute linear activation\"\"\"\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.activation(self.net_input(X)) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot class samples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=cl, \n",
    "                    edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_decision_regions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c446a8a3c88f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplot_decision_regions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mada\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Adaline - Stochastic Gradient Descent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sepal length [standardized]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_decision_regions' is not defined"
     ]
    }
   ],
   "source": [
    "ada = AdalineSGD(n_iter=15, eta=0.01, random_state=1)\n",
    "ada.fit(X_std, y)\n",
    "\n",
    "plot_decision_regions(X_std, y, classifier=ada)\n",
    "plt.title('Adaline - Stochastic Gradient Descent')\n",
    "plt.xlabel('sepal length [standardized]')\n",
    "plt.ylabel('petal length [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('images/02_15_1.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1, len(ada.cost_) + 1), ada.cost_, marker='o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Average Cost')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('images/02_15_2.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
